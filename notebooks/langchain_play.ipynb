{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb96a3a4-3356-407b-9484-37f870b1a420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "643d25a7-45f9-4d42-9c99-9c4a3adf7de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I assist you today?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(openai_api_key='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')\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "chat_model = ChatOpenAI(openai_api_key='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441d6f49-28bb-46f0-a974-6e93339b0465",
   "metadata": {},
   "source": [
    "## Core building blocks of Langchain\n",
    "\n",
    "- LLMs: what interfaces with language models\n",
    "- Prompt templates: to handle building and tear down of prompts\n",
    "- Output Parsers: to parse the output of the language model so the output is formatted the way you want it to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d622e611-c262-4460-adaf-8bbd43abf654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880e8fbe-a253-48fb-a59b-d1f0c02e9a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good title for a science fiction book about a supreme entity that we humans entropy, and the harmonious tussle with their counterpart that we call evolution?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"What is a good title for a science fiction book about a supreme entity that we humans {input_concept}, and the harmonious tussle with their counterpart that we call {output_concept}?\"\n",
    "prompt = PromptTemplate.from_template(template=prompt_template)\n",
    "prompt.format(input_concept=\"entropy\", output_concept=\"evolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38209f38-4e6c-4564-9a10-c6f94ae76899",
   "metadata": {},
   "source": [
    "## Doing more with Promptemplates\n",
    "\n",
    "You can separately format systemMessage, human_message and any other message types that you so desire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590356ae-0a6f-4f34-bddd-b82a10cfe986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d510aee6-6c8c-4205-8922-9c58c0af698b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant for Dentsply Sirona, a leader in dental machinery.', additional_kwargs={}),\n",
       " HumanMessage(content='How do i fix the carbuerator', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_template = \"You are a helpful assistant for {company}, a leader in {product}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template=system_template)\n",
    "\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(template=human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(messages=[system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat_prompt.format_messages(company=\"Dentsply Sirona\", product=\"dental machinery\", text = \"How do i fix the carbuerator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9708f43c-cbee-46cb-86a6-aed49078ef16",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "Used to convert the output from the language model into whatever format you so desire. You can crate custom classes to do this parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e788ae71-930a-4c73-9b4b-9e3313ae6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cc79962-6ee5-40a5-bfde-40722c132a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'are you good today. Maybe no', 'but also yes?']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of the language model into a comma separated list\"\"\"\n",
    "    \n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of llm call\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hello, are you good today. Maybe no, but also yes?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49737f0-2ccd-4ce3-baf9-390f77a4b75f",
   "metadata": {},
   "source": [
    "## LLM Chains \n",
    "They are the abstraction that combines the llms, the prompts and the output parsers into one composed entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a89be1cf-f632-496d-873f-fc144d707171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4df7cdc-b78b-4491-9c12-b4d9f8a96fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valve on a Dentsply Sirona dental machine?\\n\\nSystem: To fix a leaking siphon valve on a Dentsply Sirona dental machine',\n",
       " 'you will need to first turn off the main power switch. Next',\n",
       " 'use a screwdriver to remove the cover of the valve and check for any signs of damage. If the valve is cracked or broken',\n",
       " 'you will need to replace it with a new one. If the valve is not broken',\n",
       " 'you may be able to fix the leak by tightening the screws or replacing the O-ring. If the problem persists',\n",
       " 'you should contact a professional technician for assistance.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=chat_prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "\n",
    "chain.run(company=\"Dentsply Sirona\", product=\"dental machinery\", text=\"How do i fix a leaking siphon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a393c4-fc5b-49a8-9052-940025398357",
   "metadata": {},
   "source": [
    "# Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2c6dba7-87b8-40ee-bce3-f3cfaa3a786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bbd7070-6bc0-47bb-9f85-f4ac98d066f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"The Ascendance of Entropy: A Cosmic Battle for Evolution\"', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    ")\n",
    "\n",
    "chat(\n",
    "    messages=[HumanMessage(content=\"\"\"\n",
    "    What is a good title for a science fiction book about a supreme entity that we humans {input_concept}, and the harmonious tussle with their counterpart that we call {output_concept}?\n",
    "    \"\"\".format(input_concept=\"entropy\", output_concept=\"evolution\")\n",
    "                          )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643abfc5-ee5b-4dff-b8cf-1fe890a23fc9",
   "metadata": {},
   "source": [
    "## Caching In memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd422b56-e3bf-4723-9152-be584c9400ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='\"The Entropy Paradox: Unveiling the Harmonious Tussle of Evolution\"' additional_kwargs={} example=False\n",
      "Took: -1.2958116250811145\n",
      "content='\"The Entropy Paradox: Unveiling the Harmonious Tussle of Evolution\"' additional_kwargs={} example=False\n",
      "Took: -0.0012110410025343299\n",
      "content='\"The Entropy Paradox: Unveiling the Harmonious Tussle of Evolution\"' additional_kwargs={} example=False\n",
      "Took: -0.0006629589479416609\n"
     ]
    }
   ],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "import langchain\n",
    "\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "\n",
    "import time\n",
    "\n",
    "for i in range(3):\n",
    "    s = time.perf_counter()\n",
    "    print(\n",
    "        chat(\n",
    "            messages=[HumanMessage(content=\"\"\"\n",
    "            What is a good title for a science fiction book about a supreme entity that we humans {input_concept}, and the harmonious tussle with their counterpart that we call {output_concept}?\n",
    "            \"\"\".format(input_concept=\"entropy\", output_concept=\"evolution\")\n",
    "                                  )]\n",
    "        )\n",
    "    )\n",
    "    e = time.perf_counter()\n",
    "    print(f\"Took: {e-s}\"h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be3abb0-8715-4400-a874-1770de6c96d0",
   "metadata": {},
   "source": [
    "## Sqlite Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f613e-553f-4fc0-a915-fe114d0448a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "langchain.llm_cache = SQLiteCache(database_path=\".langchain.db\")\n",
    "\n",
    "for i in range(3):\n",
    "    s = time.perf_counter()\n",
    "    print(\n",
    "        chat(\n",
    "            messages=[HumanMessage(content=\"\"\"\n",
    "            What is a good title for a science fiction book about a supreme entity that we humans {input_concept}, and the harmonious tussle with their counterpart that we call {output_concept}?\n",
    "            \"\"\".format(input_concept=\"entropy\", output_concept=\"evolution\")\n",
    "                                  )]\n",
    "        )\n",
    "    )\n",
    "    e = time.perf_counter()\n",
    "    print(f\"Took: {e-s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba86f9d-0c4b-4de1-aabe-cebc7fff8f1c",
   "metadata": {},
   "source": [
    "## Using Prompts with ChatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59f870b4-8860-4fed-9b63-77b5fe190c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "मनुष्य का उद्देश्य है अनविकसित स्थानों में विकसित होना। (Manushya ka uddeshya hai anvikasit sthanon mein viksit hona)content='मनुष्य का उद्देश्य है अनविकसित स्थानों में विकसित होना। (Manushya ka uddeshya hai anvikasit sthanon mein viksit hona)' additional_kwargs={} example=False\n",
      "Oh, radiant soul, you are the symphony of stardust, the celestial dance of cosmic marvels. Your essence, a tapestry woven with threads of moonlight and whispers of forgotten constellations, illuminates the universe with an unparalleled brilliance. Your mere presence is a testament to the boundless creativity of the cosmos, a masterpiece painted with hues unseen by mortal eyes. In your every step, the universe rejoices, for you are the embodiment of the extraordinary, the embodiment of a thousand untold tales waiting to be written."
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    template = \"You are a helpful assistant that translates from {input_language} to {output_language}\"\n",
    ")\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    template = \"{text}\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")\n",
    "\n",
    "print(\n",
    "    chat(\n",
    "        chat_prompt.format_prompt(\n",
    "            input_language=\"English\",\n",
    "            output_language=\"Hindi\",\n",
    "            text=\"Man's purpose is to grow into places ungrown\"\n",
    "        ).to_messages()\n",
    "    )\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0, openai_api_key=\"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\")\n",
    "resp = chat([HumanMessage(content=\"Praise me in the most unique unheard way possible.\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6ffb0-f226-4021-b642-e29cdc48026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    ")\n",
    "\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "chat = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0, openai_api_key=\"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\")\n",
    "resp = chat([HumanMessage(content=\"Write me a song about sparkling water.\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2708af12-1ad5-4d8b-8c95-90755124ec61",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "For when you want to transform the output into a specific format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf3556e6-95eb-465c-8d45-303187e2fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c547196b-0208-47c7-b714-8060ec893040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our desired data structure\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up the joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # you can add custom validation logid\n",
    "    @validator('setup')\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != '?':\n",
    "            raise ValueError(\"Badly formed question\")\n",
    "        return field\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10d300e7-b999-40ea-997b-c317f4355fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the playground?', punchline='To get to the other slide!')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up a parser that uses the pydantic model\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "# set up the prompt i guess to pass to the llm\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=['query'],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# lets work the prompt\n",
    "_output = llm(prompt.format_prompt(query=\"Tell me a joke\").to_string())\n",
    "parser.parse(_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4bc125df-2168-4fba-ac13-d5525fc025f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s='' t='hello'\n"
     ]
    }
   ],
   "source": [
    "s = \"hello\"\n",
    "t = s\n",
    "s = \"\"\n",
    "print(f\"{s=} {t=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06dc1d-11c1-4c2b-85cf-9cc93f460fcd",
   "metadata": {},
   "source": [
    "## Basic things that i should be able to do \n",
    "\n",
    "### Tasks\n",
    "- [x] embed a query \n",
    "- [x] do a similarity search on an embedding against a big vector store\n",
    "- [ ] change system message in a chat conversation.\n",
    "- [ ] pass memory to the chat\n",
    "- [ ] retreive nodes based on conversation memory\n",
    "- [ ] self extract metadata from the node content\n",
    "- [ ] swap out and/or add evidence into a context constructor\n",
    "- [ ] do three calls simultaneously not sequentially\n",
    "\n",
    "### To understand\n",
    "- [ ] how does system message work, is it set once per session or multiple times? \n",
    "- [ ] prompts - how to work with prompt templates\n",
    "- [ ] how to store memory in chat messages \n",
    "- [ ] how to store chat messages? As embedding?\n",
    "- [ ] how to store metadata? How to query against it \n",
    "- [ ] generate self metadata\n",
    "- [ ] Parts of an agent \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b19d1a-dd15-4e40-aa6a-f601d894fb3c",
   "metadata": {},
   "source": [
    "### Embed a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ec9fdb-4549-4fbd-a712-b0a9c8645d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: Hi, I am a supplier of dental machinery. What company could I be?\n",
      "[('Hello, how are you?', 1536), ('I am ok, and you?', 1536), ('Nice weather ha this?', 1536), ('Yeah, weather like this and you want to kill everyday', 1536)]\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embedding_generation_model = OpenAIEmbeddings(openai_api_key='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')\n",
    "\n",
    "# embed a single query\n",
    "query = \"Hi, I am a supplier of dental machinery. What company could I be?\"\n",
    "query_embedding = embedding_generation_model.embed_query(query)\n",
    "print(f\"query: {query}\")\n",
    "\n",
    "# embed a list of documents\n",
    "doc_list = [\"Hello, how are you?\", \"I am ok, and you?\", \"Nice weather ha this?\", \"Yeah, weather like this and you want to kill everyday\"]\n",
    "doc_embeddings = embedding_generation_model.embed_documents(doc_list)\n",
    "print([(doc, len(embedding)) for doc, embedding in zip(doc_list, doc_embeddings)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d38a2d-4540-414f-977d-c1c11d1d6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_descriptions = {\n",
    "    \"CEREC Primemill\": \"This is an device that is used for computed-aided production of dental restorations, abutments, parts of abutments and drilling templates for implant placement.\",\n",
    "    \"Primescan Connect\": \"Primescan Connect allows you to create digital impressions for detnal purposes and send digital scans to a laboratory of your choice to manufacture at your laboratory partner.\",\n",
    "    \"CEREC SW 5\": \"\"\"\n",
    "    The CEREC SW 5 software is used to create optical impressions of dentulous, partially edentulous or completely edentulous jaw situations. Digital models of the jaw situations are created in CEREC SW 5 based on the optical impressions. The designs can be exported for preparation from dental materials.\n",
    "    \"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d518eb6d-6f5b-4e35-8dd0-88508e5caa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator, EmbeddingDistance\n",
    "\n",
    "openai_evaluator = load_evaluator(\"embedding_distance\", embeddings=embedding_generation_model)\n",
    "\n",
    "while True:\n",
    "    q = input(\"Query to check similarity --> \")\n",
    "    for desc in product_descriptions.values():\n",
    "        print(openai_evaluator.evaluate_strings(prediction=q, reference=desc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poc-demo-pdf",
   "language": "python",
   "name": "poc-demo-pdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
